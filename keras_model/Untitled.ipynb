{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, LSTM, Input, Embedding, Lambda, Flatten, Dense, Softmax, TimeDistributed\n",
    "import keras.backend as K\n",
    "from keras.activations import sigmoid, relu\n",
    "from layers import *\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from params import Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_embedding = Input(shape=(Params.max_passage_count, Params.max_passage_len, Params.embedding_dim), \n",
    "                                dtype=\"float32\", name=\"passages_embedding\")\n",
    "question_embedding = Input(shape=(Params.max_question_len, Params.embedding_dim),\n",
    "                        dtype=\"float32\", name=\"question_embedding\")\n",
    "\n",
    "encode_layer = Bidirectional(LSTM(Params.embedding_dim, #recurrent_keep_prob=1-Params.encoder_dropout, \n",
    "                            return_sequences=True), name=\"input_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lee/.conda/envs/flyai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"input_encoder/concat:0\", shape=(?, ?, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "question_encoding = encode_layer(question_embedding);\n",
    "print(question_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_encoding = TimeDistributed(encode_layer, name=\"passage_encoding\")(passages_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'passage_encoding_3/Reshape_1:0' shape=(?, 5, 200, 128) dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(inputs):\n",
    "    return K.concatenate(inputs)\n",
    "Concat = Lambda(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextEncoding(Layer):\n",
    "    def __init__(self, question_encoding, **kwargs):\n",
    "        self.question_encoding = question_encoding\n",
    "        super(ContextEncoding, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.c2qAttention = C2QAttention(name=\"context_to_query_attention\")\n",
    "        self.c2qAttention.build(input_shape)\n",
    "        self.q2cAttention =  Q2CAttention(name='query_to_context_attention')\n",
    "        self.q2cAttention.build(input_shape)\n",
    "        self.mergedContext = MergedContext(name='merged_context')\n",
    "        self.mergedContext.build(input_shape)\n",
    "\n",
    "        self.trainable_weights = self.c2qAttention.trainable_weights + self.q2cAttention.trainable_weights + self.mergedContext.trainable_weights\n",
    "        super(ContextEncoding, self).build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, passage_encoding):\n",
    "        question_encoding = self.question_encoding\n",
    "        print(passage_encoding)\n",
    "        # question_encoding, passage_encoding = input\n",
    "        score_matrix = K.squeeze(K.dot(passage_encoding, K.permute_dimensions(self.question_encoding, (0, 2, 1))), axis=-1)\n",
    "        print(score_matrix)\n",
    "        context_to_query_attention = self.c2qAttention([\n",
    "                                                    score_matrix, question_encoding])\n",
    "        print(context_to_query_attention)\n",
    "        query_to_context_attention = self.q2cAttention([score_matrix, passage_encoding])\n",
    "\n",
    "        merged_context = self.mergedContext(\n",
    "                                [passage_encoding, context_to_query_attention, query_to_context_attention])\n",
    "        \n",
    "        print(passage_encoding)\n",
    "        print(context_to_query_attention)\n",
    "        print(query_to_context_attention)\n",
    "        \n",
    "        # modeled_passage = Bidirectional(LSTM(50, recurrent_dropout=0.2, return_sequences=True), name=\"passage_context_encoding\")(modeled_passage)\n",
    "        return merged_context\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print(input_shape)\n",
    "        return (None, input_shape[1], 512)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_4/Reshape:0\", shape=(?, 200, 128), dtype=float32)\n",
      "Tensor(\"time_distributed_4/Squeeze:0\", shape=(?, 200, ?), dtype=float32)\n",
      "Tensor(\"time_distributed_4/context_to_query_attention/Sum:0\", shape=(?, 200, 128), dtype=float32)\n",
      "Tensor(\"time_distributed_4/Reshape:0\", shape=(?, 200, 128), dtype=float32)\n",
      "Tensor(\"time_distributed_4/context_to_query_attention/Sum:0\", shape=(?, 200, 128), dtype=float32)\n",
      "Tensor(\"time_distributed_4/query_to_context_attention/Tile:0\", shape=(?, ?, 128), dtype=float32)\n",
      "(None, 200, 128)\n",
      "(None, 200, 128)\n"
     ]
    }
   ],
   "source": [
    "passage_context = TimeDistributed(ContextEncoding(question_encoding))(passage_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e5c81684d98e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mscore_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_encoding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'score_matrix' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'time_distributed_7/Reshape_4:0' shape=(?, 5, 200, 512) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_passage_layer = Bidirectional(LSTM(Params.embedding_dim, recurrent_dropout=0.2, return_sequences=True), name=\"passage_modeling2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_modeling = TimeDistributed(model_passage_layer, name=\"passage_modeling\")(passage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'passage_modeling_1/Reshape_1:0' shape=(?, 5, 200, 128) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, 5, 200, 640) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.concatenate([passage_context, passage_modeling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_17/Reshape:0\", shape=(?, 200, 640), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "span_begin_probabilities = TimeDistributed(SpanBegin(name='span_begin'))(Concat([passage_context, passage_modeling]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_begin_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_end_representation = SpanEndRepresentation([passage_context, passage_modeling, span_begin_probabilities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_end_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_end_representation = TimeDistributed(Bidirectional(LSTM(Params.embedding_dim, return_sequences=True)), name=\"span_end_lstm\")(span_end_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'span_end_lstm/Reshape_1:0' shape=(?, 5, 200, 128) dtype=float32>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_end_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.concatenate([passage_context, span_end_representation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 200)\n",
      "(None, 200)\n"
     ]
    }
   ],
   "source": [
    "span_end_probabilities = TimeDistributed(SpanEnd(name=\"span_end_probability\"))(Concat([passage_context, span_end_representation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'span_end_probabilities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-bbf75b7f1c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspan_end_probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'span_end_probabilities' is not defined"
     ]
    }
   ],
   "source": [
    "span_end_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_13/Reshape_1:0\", shape=(?, 5, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "content_indices = TimeDistributed(ContentIndice(name=\"content_indice\"))(passage_modeling);\n",
    "print(content_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"answer_encoding/Sum:0\", shape=(?, 5, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "answer_encoding = AnswerEncoding([passages_embedding, content_indices]);\n",
    "print(answer_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.permute_dimensions(answer_encoding, (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = K.dot(answer_encoding, K.permute_dimensions(answer_encoding, (0, 2, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.squeeze(matrix, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.matmul(answer_encoding, K.permute_dimensions(answer_encoding, (0, 2, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze:0\", shape=(?, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "score_matrix = K.squeeze(K.dot(answer_encoding, K.permute_dimensions(answer_encoding, (0, 2, 1))), axis=-2);\n",
    "print(score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye1 = K.eye(5)\n",
    "zero1 = K.zeros_like(eye1)\n",
    "mask = K.cast(K.equal(eye1, zero1), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_matrix = score_matrix * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"softmax_15/truediv:0\", shape=(?, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "score_matrix = Softmax(axis=-1)(score_matrix);\n",
    "print(score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze_1:0\", shape=(?, 5, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "answer_encoding_hat = K.squeeze(K.dot(score_matrix, answer_encoding), axis=-2);\n",
    "print(answer_encoding_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_5:0\", shape=(?, 5, 600), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "answer_encoding_final = K.concatenate([answer_encoding, answer_encoding_hat, answer_encoding*answer_encoding_hat]);\n",
    "print(answer_encoding_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"softmax_16/truediv:0\", shape=(?, 5, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "answer_probability = Dense(1)(answer_encoding_final);\n",
    "answer_probability = Softmax(axis=-1)(answer_probability)\n",
    "print(answer_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze_2:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "answer_probability = K.squeeze(answer_probability, axis=-1);\n",
    "print(answer_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerProbability(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AnswerProbability, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: (None, 5, 200)\n",
    "        self.dense_1 = Dense(1, activation=\"relu\")\n",
    "        self.dense_1.build(input_shape[:-1] + (3*input_shape[-1],))\n",
    "        self.trainable_weights = self.dense_1.trainable_weights\n",
    "        \n",
    "        super(AnswerProbability, self).build(input_shape)\n",
    "    \n",
    "    def call(self, answer_encoding):\n",
    "        score_matrix = K.squeeze(K.dot(answer_encoding, K.permute_dimensions(answer_encoding, (0, 2, 1))), axis=-2)\n",
    "        eye1 = K.eye(Params.max_passage_count); zero1 = K.zeros_like(eye1); mask = K.cast(K.equal(eye1, zero1), dtype=\"float32\")\n",
    "        score_matrix = score_matrix * mask\n",
    "        score_matrix = Softmax(axis=-1)(score_matrix)\n",
    "        answer_encoding_hat = K.squeeze(K.dot(score_matrix, answer_encoding), axis=-2)\n",
    "        answer_encoding_final = K.concatenate([answer_encoding, answer_encoding_hat, answer_encoding*answer_encoding_hat])\n",
    "        answer_probability = Dense(1)(answer_encoding_final);\n",
    "        answer_probability = Softmax(axis=-1)(answer_probability)\n",
    "        answer_probability = K.squeeze(answer_probability, axis=-1)\n",
    "        return answer_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"answer_probability_2/Squeeze_2:0\", shape=(?, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "answer_probability = AnswerProbability()(answer_encoding);\n",
    "print(answer_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model([passages_embedding, question_embedding], [answer_probability, span_begin_probabilities, span_end_probabilities, content_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"time_distributed_14/Reshape:0\", shape=(?, 200, 640), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "span_begin_probabilities = TimeDistributed(SpanBegin(name='span_begin'))(K.concatenate([passage_context, passage_modeling]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([passages_embedding, question_embedding], [span_begin_probabilities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([passages_embedding, question_embedding], [answer_probability])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "passages_embedding (InputLayer) (None, 5, 200, 64)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "passage_encoding (TimeDistribut (None, 5, 200, 128)  66048       passages_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 5, 200, 512)  0           passage_encoding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "passage_modeling (TimeDistribut (None, 5, 200, 128)  295424      time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 5, 200, 640)  0           time_distributed_7[0][0]         \n",
      "                                                                 passage_modeling[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 5, 200)       641         lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 362,113\n",
      "Trainable params: 362,113\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "passages_embedding (InputLayer) (None, 5, 200, 64)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "passage_encoding (TimeDistribut (None, 5, 200, 128)  66048       passages_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 5, 200, 512)  0           passage_encoding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "passage_modeling (TimeDistribut (None, 5, 200, 128)  295424      time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 5, 200)       8321        passage_modeling[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "answer_encoding (Lambda)        (None, 5, 200)       0           passages_embedding[0][0]         \n",
      "                                                                 time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "answer_probability_2 (AnswerPro (None, 5, 200)       601         answer_encoding[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 370,394\n",
      "Trainable params: 370,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.log(answer_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_matrix = tf.Variable([[1, 2], [2, 3]])\n",
    "mask = tf.Variable([[0, 1], [1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(score_matrix * mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.dot(score_matrix, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(tf.logical_not(tf.cast(tf.matrix_diag([1] * 5), tf.bool)), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye1 = K.eye(3)\n",
    "zeor1 = K.zeros_like(eye)\n",
    "mask = K.cast(K.equal(eye1, zero1), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?K.zeros_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?K.eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m = passage_modeling[:, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-aa6e1d2ca226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p_m' is not defined"
     ]
    }
   ],
   "source": [
    "p_1 = Dense(Params.embedding_dim, activation=\"relu\")(p_m);\n",
    "print(p_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2 = Dense(1, activation=\"relu\")(p_1);\n",
    "print(p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Softmax(axis=-1)(K.squeeze(p_2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-62c5d05c485d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'content_indices' is not defined"
     ]
    }
   ],
   "source": [
    "K.expand_dims(content_indices, axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.expand_dims(content_indices, axis=-1) * passages_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c528bc5eba9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpassages_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'content_indices' is not defined"
     ]
    }
   ],
   "source": [
    "K.sum(K.expand_dims(content_indices, axis=-1) * passages_embedding, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-13-701968f285c2>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-701968f285c2>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class AnswerProbability(Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(AnswerProbability, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "    \n",
    "    \"\"\"\n",
    "        input: (None, Params.max_passage_count, Pararms.max_passage_len)\n",
    "        output: (None, Params.max_passage_count)\n",
    "    \"\"\"\n",
    "    def call(self, answer_encoding):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerEncoding(inputs):\n",
    "    passage_embedding, indice_probability = inputs\n",
    "    answer_encoding = K.expand_dims(indice_probability, axis=-1) * passage_embedding\n",
    "    answer_encoding = K.sum(answer_encoding, axis=-1)\n",
    "    return answer_encoding\n",
    "AnswerEncoding = Lambda(answerEncoding, name=\"answer_encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanEnd(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpanEnd, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_shape_dense_1 = input_shape[:-1] + (Params.embedding_dim*10, )\n",
    "        self.dense_1 = Dense(units=1)\n",
    "        self.dense_1.build(input_shape_dense_1)\n",
    "        self.trainable_weights = self.dense_1.trainable_weights\n",
    "        super(SpanEnd, self).build(input_shape)\n",
    "\n",
    "    def call(self, span_end_input):\n",
    "        span_end_weights = TimeDistributed(self.dense_1)(span_end_input)\n",
    "\n",
    "        span_end_probabilities = Softmax()(K.squeeze(span_end_weights, axis=-1))\n",
    "        return span_end_probabilities\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print(input_shape[:-1])\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanBegin(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpanBegin, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: (None, 200, embeddim*8+embeddim*2)\n",
    "        self.dense_1 = Dense(units=1)\n",
    "        self.dense_1.build(input_shape)\n",
    "        self.trainable_weights = self.dense_1.trainable_weights\n",
    "        super(SpanBegin, self).build(input_shape)\n",
    "\n",
    "    def call(self, span_begin_input):\n",
    "        print(span_begin_input)\n",
    "        # span_begin_input = K.concatenate([merged_context, modeled_passage])\n",
    "        span_begin_weights = TimeDistributed(self.dense_1)(span_begin_input)\n",
    "        span_begin_probabilities = Softmax()(K.squeeze(span_begin_weights, axis=-1))\n",
    "        return span_begin_probabilities\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def span_end_representation(inputs):\n",
    "    passage_context, passage_modeling, span_probabilities = inputs\n",
    "    \n",
    "    weighted_sum = K.sum(K.expand_dims(span_begin_probabilities, axis=-1) * passage_modeling, axis=-2)\n",
    "    passage_weighted_by_predicted_span = K.expand_dims(weighted_sum, axis=-2)\n",
    "    passage_weighted_by_predicted_span = K.tile(passage_weighted_by_predicted_span, [1, 1, Params.max_passage_len, 1])\n",
    "    multiply = passage_modeling * passage_weighted_by_predicted_span\n",
    "    \n",
    "    return K.concatenate([passage_context, passage_modeling, passage_weighted_by_predicted_span, multiply])\n",
    "\n",
    "SpanEndRepresentation = Lambda(span_end_representation, name=\"span_end_representation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentIndice(Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(ContentIndice, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.dense_1 = Dense(Params.embedding_dim, activation=\"relu\")\n",
    "        self.dense_1.build(input_shape)\n",
    "        self.dense_2 = Dense(1, activation=\"relu\")\n",
    "        self.dense_2.build(input_shape[:-1] + (Params.embedding_dim, ))\n",
    "        self.trainable_weights = self.dense_1.trainable_weights + self.dense_2.trainable_weights\n",
    "        \n",
    "        super(ContentIndice, self).build(input_shape)\n",
    "        \n",
    "    def call(self, passage_modeling):\n",
    "        passage_representation = self.dense_1(passage_modeling)\n",
    "        passage_representation = self.dense_2(passage_representation)\n",
    "        passage_representation = K.squeeze(passage_representation, axis=-1)\n",
    "        passage_indices = Softmax(axis=-1)(passage_representation)\n",
    "        return passage_indices\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'span_begin_probabilities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b5b8869b58fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweighted_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_begin_probabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpassage_modeling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'span_begin_probabilities' is not defined"
     ]
    }
   ],
   "source": [
    "weighted_sum = K.sum(K.expand_dims(span_begin_probabilities, axis=-1) * passage_modeling, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weighted_sum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5efe6f577fb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweighted_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'weighted_sum' is not defined"
     ]
    }
   ],
   "source": [
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weighted_sum' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-25d8264dab25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpassage_weighted_by_predicted_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'weighted_sum' is not defined"
     ]
    }
   ],
   "source": [
    "passage_weighted_by_predicted_span = K.expand_dims(weighted_sum, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_weighted_by_predicted_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'passage_weighted_by_predicted_span' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-11a5a12e633b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpassage_weighted_by_predicted_span\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassage_weighted_by_predicted_span\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_passage_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'passage_weighted_by_predicted_span' is not defined"
     ]
    }
   ],
   "source": [
    "passage_weighted_by_predicted_span = K.tile(passage_weighted_by_predicted_span, [1, 1, Params.max_passage_len, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'passage_weighted_by_predicted_span' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2a4176794bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpassage_weighted_by_predicted_span\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'passage_weighted_by_predicted_span' is not defined"
     ]
    }
   ],
   "source": [
    "passage_weighted_by_predicted_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'passage_modeling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c579e1144142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultiply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpassage_modeling\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpassage_weighted_by_predicted_span\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'passage_modeling' is not defined"
     ]
    }
   ],
   "source": [
    "multiply = passage_modeling * passage_weighted_by_predicted_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multiply' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d8ca8d133468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultiply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'multiply' is not defined"
     ]
    }
   ],
   "source": [
    "multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextEncoding(Layer):\n",
    "    def __init__(self, question_encoding, **kwargs):\n",
    "        self.question_encoding = question_encoding\n",
    "        super(ContextEncoding, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.c2qAttention = C2QAttention(name=\"context_to_query_attention\")\n",
    "        self.c2qAttention.build(input_shape)\n",
    "        self.q2cAttention =  Q2CAttention(name='query_to_context_attention')\n",
    "        self.q2cAttention.build(input_shape)\n",
    "        self.mergedContext = MergedContext(name='merged_context')\n",
    "        self.mergedContext.build(input_shape)\n",
    "\n",
    "        self.trainable_weights = self.c2qAttention.trainable_weights + self.q2cAttention.trainable_weights + self.mergedContext.trainable_weights\n",
    "        super(ContextEncoding, self).build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, passage_encoding):\n",
    "        question_encoding = self.question_encoding\n",
    "        # question_encoding, passage_encoding = input\n",
    "        score_matrix = K.squeeze(K.dot(passage_encoding, K.permute_dimensions(self.question_encoding, (0, 2, 1))), axis=-1)\n",
    "\n",
    "        context_to_query_attention = self.c2qAttention([\n",
    "                                                    score_matrix, question_encoding])\n",
    "        query_to_context_attention = self.q2cAttention([score_matrix, passage_encoding])\n",
    "\n",
    "        merged_context = self.mergedContext(\n",
    "                                [passage_encoding, context_to_query_attention, query_to_context_attention])\n",
    "\n",
    "        # modeled_passage = Bidirectional(LSTM(50, recurrent_dropout=0.2, return_sequences=True), name=\"passage_context_encoding\")(modeled_passage)\n",
    "        return merged_context\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print(input_shape)\n",
    "        return (None, input_shape[1], 512)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanEnd(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpanEnd, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        embdim = Params.embdim\n",
    "        input_shape_bilstm_1 = input_shape[0][:-1] + (embdim*14, )\n",
    "        self.bilstm_1 = Bidirectional(LSTM(emdim, return_sequences=True))\n",
    "        self.bilstm_1.build(input_shape_bilstm_1)\n",
    "        input_shape_dense_1 = input_shape[0][:-1] + (emdim*10, )\n",
    "        self.dense_1 = Dense(units=1)\n",
    "        self.dense_1.build(input_shape_dense_1)\n",
    "        self.trainable_weights = self.bilstm_1.trainable_weights + self.dense_1.trainable_weights\n",
    "        super(SpanEnd, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded_passage, merged_context, modeled_passage, span_begin_probabilities = inputs\n",
    "        weighted_sum = K.sum(K.expand_dims(span_begin_probabilities, axis=-1) * modeled_passage, -2)\n",
    "        passage_weighted_by_predicted_span = K.expand_dims(weighted_sum, axis=1)\n",
    "        tile_shape = K.concatenate([[1], [K.shape(encoded_passage)[1]], [1]], axis=0)\n",
    "        passage_weighted_by_predicted_span = K.tile(passage_weighted_by_predicted_span, tile_shape)\n",
    "        multiply1 = modeled_passage * passage_weighted_by_predicted_span\n",
    "        span_end_representation = K.concatenate(\n",
    "            [merged_context, modeled_passage, passage_weighted_by_predicted_span, multiply1])\n",
    "        \n",
    "        span_end_representation = self.bilstm_1(span_end_representation)\n",
    "\n",
    "        span_end_input = K.concatenate([merged_context, span_end_representation])\n",
    "\n",
    "        span_end_weights = TimeDistributed(self.dense_1)(span_end_input)\n",
    "\n",
    "        span_end_probabilities = Softmax()(K.squeeze(span_end_weights, axis=-1))\n",
    "        return span_end_probabilities\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        _, merged_context_shape, _, _ = input_shape\n",
    "        return merged_context_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Q2CAttention(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Q2CAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Q2CAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        similarity_matrix, encoded_context = inputs\n",
    "        max_similarity = K.max(similarity_matrix, axis=-1)\n",
    "        # by default, axis = -1 in Softmax\n",
    "        context_to_query_attention = Softmax()(max_similarity)\n",
    "        weighted_sum = K.sum(K.expand_dims(context_to_query_attention, axis=-1) * encoded_context, -2)\n",
    "        expanded_weighted_sum = K.expand_dims(weighted_sum, 1)\n",
    "        num_of_repeatations = K.shape(encoded_context)[1]\n",
    "        return K.tile(expanded_weighted_sum, [1, num_of_repeatations, 1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        similarity_matrix_shape, encoded_context_shape = input_shape\n",
    "        return similarity_matrix_shape[:-1] + encoded_context_shape[-1:]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers.advanced_activations import Softmax\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class C2QAttention(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(C2QAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(C2QAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        similarity_matrix, encoded_question = inputs\n",
    "        context_to_query_attention = Softmax(axis=-1)(similarity_matrix)\n",
    "        encoded_question = K.expand_dims(encoded_question, axis=1)\n",
    "        return K.sum(K.expand_dims(context_to_query_attention, axis=-1) * encoded_question, -2)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        similarity_matrix_shape, encoded_question_shape = input_shape\n",
    "        return similarity_matrix_shape[:-1] + encoded_question_shape[-1:]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class MergedContext(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MergedContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(MergedContext, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded_context, context_to_query_attention, query_to_context_attention = inputs\n",
    "        element_wise_multiply1 = encoded_context * context_to_query_attention\n",
    "        element_wise_multiply2 = encoded_context * query_to_context_attention\n",
    "        concatenated_tensor = K.concatenate(\n",
    "            [encoded_context, context_to_query_attention, element_wise_multiply1, element_wise_multiply2], axis=-1)\n",
    "        return concatenated_tensor\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        encoded_context_shape, _, _ = input_shape\n",
    "        return encoded_context_shape[:-1] + (encoded_context_shape[-1] * 4, )\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flyai",
   "language": "python",
   "name": "flyai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
